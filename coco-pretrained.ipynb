{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4233,
     "status": "ok",
     "timestamp": 1621523267021,
     "user": {
      "displayName": "Camus Shen",
      "photoUrl": "",
      "userId": "08908240325552421641"
     },
     "user_tz": -480
    },
    "id": "tQY4EBLmbMKE",
    "outputId": "eee3ad7a-f64d-45cc-fdbb-aa03d5930bf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: runipy in /usr/local/lib/python3.7/dist-packages (0.1.5)\n",
      "Requirement already satisfied: Pygments>=1.6 in /usr/local/lib/python3.7/dist-packages (from runipy) (2.6.1)\n",
      "Requirement already satisfied: Jinja2>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from runipy) (2.11.3)\n",
      "Requirement already satisfied: nbconvert>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from runipy) (5.6.1)\n",
      "Requirement already satisfied: ipykernel>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from runipy) (4.10.1)\n",
      "Requirement already satisfied: nbformat>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from runipy) (5.1.3)\n",
      "Requirement already satisfied: ipython>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from runipy) (5.5.0)\n",
      "Requirement already satisfied: pyzmq>=14.1.0 in /usr/local/lib/python3.7/dist-packages (from runipy) (22.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.7.2->runipy) (2.0.0)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert>=4.0.0->runipy) (0.4.4)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert>=4.0.0->runipy) (3.3.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert>=4.0.0->runipy) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=4.0.0->runipy) (1.4.3)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=4.0.0->runipy) (0.3)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbconvert>=4.0.0->runipy) (4.7.1)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=4.0.0->runipy) (5.0.5)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert>=4.0.0->runipy) (0.8.4)\n",
      "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.0.0->runipy) (5.1.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.0.0->runipy) (5.3.5)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.0.0->runipy) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.0.0->runipy) (2.6.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=2.3.1->runipy) (4.8.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=2.3.1->runipy) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=2.3.1->runipy) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=2.3.1->runipy) (1.0.18)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=2.3.1->runipy) (56.1.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=2.3.1->runipy) (0.8.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert>=4.0.0->runipy) (20.9)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert>=4.0.0->runipy) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert>=4.0.0->runipy) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.0.0->runipy) (2.8.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=2.3.1->runipy) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=2.3.1->runipy) (0.2.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bleach->nbconvert>=4.0.0->runipy) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install runipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnNXNQCjdniL"
   },
   "outputs": [],
   "source": [
    "# If you forked the repository, you can replace the link.\n",
    "repo_url = 'https://github.com/Tony607/object_detection_demo'\n",
    "\n",
    "# Number of training steps.\n",
    "num_steps = 1000  # 200000\n",
    "\n",
    "# Number of evaluation steps.\n",
    "num_eval_steps = 50\n",
    "\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
    "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "    'faster_rcnn_inception_v2': {\n",
    "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
    "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
    "        'batch_size': 12\n",
    "    },\n",
    "    'rfcn_resnet101': {\n",
    "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
    "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
    "        'batch_size': 8\n",
    "    }\n",
    "}\n",
    "\n",
    "# Pick the model you want to use\n",
    "# Select a model in `MODELS_CONFIG`.\n",
    "selected_model = 'ssd_mobilenet_v2'\n",
    "\n",
    "# Name of the object detection model to use.\n",
    "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
    "\n",
    "# Name of the pipline file in tensorflow object detection API.\n",
    "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
    "\n",
    "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
    "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4950,
     "status": "ok",
     "timestamp": 1621523267751,
     "user": {
      "displayName": "Camus Shen",
      "photoUrl": "",
      "userId": "08908240325552421641"
     },
     "user_tz": -480
    },
    "id": "dxc3DmvLQF3z",
    "outputId": "0d7e3016-f1af-4d77-a90f-44531bff421c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "fatal: destination path 'object_detection_demo' already exists and is not an empty directory.\n",
      "/content/object_detection_demo\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "%cd /content\n",
    "\n",
    "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
    "\n",
    "!git clone {repo_url}\n",
    "%cd {repo_dir_path}\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15234,
     "status": "ok",
     "timestamp": 1621523278042,
     "user": {
      "displayName": "Camus Shen",
      "photoUrl": "",
      "userId": "08908240325552421641"
     },
     "user_tz": -480
    },
    "id": "ecpHEnka8Kix",
    "outputId": "ab2b9db5-5aaa-4795-a6dd-f77639dc509f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "fatal: destination path 'models' already exists and is not an empty directory.\n",
      "/content/models/research\n",
      "2021-05-20 15:07:54.591832: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Traceback (most recent call last):\n",
      "  File \"object_detection/builders/model_builder_test.py\", line 21, in <module>\n",
      "    from object_detection.builders import model_builder\n",
      "  File \"/content/models/research/object_detection/builders/model_builder.py\", line 23, in <module>\n",
      "    from object_detection.builders import anchor_generator_builder\n",
      "  File \"/content/models/research/object_detection/builders/anchor_generator_builder.py\", line 23, in <module>\n",
      "    from object_detection.anchor_generators import flexible_grid_anchor_generator\n",
      "  File \"/content/models/research/object_detection/anchor_generators/flexible_grid_anchor_generator.py\", line 19, in <module>\n",
      "    from object_detection.anchor_generators import grid_anchor_generator\n",
      "  File \"/content/models/research/object_detection/anchor_generators/grid_anchor_generator.py\", line 27, in <module>\n",
      "    from object_detection.utils import ops\n",
      "  File \"/content/models/research/object_detection/utils/ops.py\", line 28, in <module>\n",
      "    import tf_slim as slim\n",
      "ModuleNotFoundError: No module named 'tf_slim'\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "!git clone --quiet https://github.com/tensorflow/models.git\n",
    "\n",
    "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
    "\n",
    "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
    "\n",
    "!pip install -q pycocotools\n",
    "\n",
    "%cd /content/models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
    "\n",
    "!python object_detection/builders/model_builder_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-k7uGThXlny"
   },
   "source": [
    "Use the following scripts to generate the `tfrecord` files.\n",
    "```bash\n",
    "# Convert train folder annotation xml files to a single csv file,\n",
    "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
    "python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
    "\n",
    "# Convert test folder annotation xml files to a single csv.\n",
    "python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
    "\n",
    "# Generate `train.record`\n",
    "python generate_tfrecord.py --csv_input=data/annotations/train_labels.csv --output_path=data/annotations/train.record --img_path=data/images/train --label_map data/annotations/label_map.pbtxt\n",
    "\n",
    "# Generate `test.record`\n",
    "python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15227,
     "status": "ok",
     "timestamp": 1621523278042,
     "user": {
      "displayName": "Camus Shen",
      "photoUrl": "",
      "userId": "08908240325552421641"
     },
     "user_tz": -480
    },
    "id": "v_6vXFfTbq4Z",
    "outputId": "48dc6bce-8210-4dc6-de0f-bd1e2acce666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/models/research\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezGDABRXXhPP"
   },
   "outputs": [],
   "source": [
    "# %cd {repo_dir_path}\n",
    "\n",
    "# Convert train folder annotation xml files to a single csv file,\n",
    "# generate the `label_map.pbtxt` file to `data/` directory as well.\n",
    "# !python xml_to_csv.py -i data/images/train -o data/annotations/train_labels.csv -l data/annotations\n",
    "\n",
    "# Convert test folder annotation xml files to a single csv.\n",
    "# !python xml_to_csv.py -i data/images/test -o data/annotations/test_labels.csv\n",
    "\n",
    "# Generate `train.record`\n",
    "# !python \"/content/drive/MyDrive/Colab Notebooks/Untitled4.py\" --csv_input=/content/drive/MyDrive/cv/hw2/labels.csv --output_path=train.record --img_path=drive/MyDrive/cv/hw2/train --label_map label_map.pbtxt\n",
    "\n",
    "# Generate `test.record`\n",
    "# !python generate_tfrecord.py --csv_input=data/annotations/test_labels.csv --output_path=data/annotations/test.record --img_path=data/images/test --label_map data/annotations/label_map.pbtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tgd-fzAIkZlV"
   },
   "outputs": [],
   "source": [
    "# test_record_fname = '/content/object_detection_demo/data/annotations/test.record'\n",
    "train_record_fname = 'drive/MyDrive/train.tfrecord'\n",
    "label_map_pbtxt_fname = '/content/drive/MyDrive/label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20282,
     "status": "ok",
     "timestamp": 1621523283109,
     "user": {
      "displayName": "Camus Shen",
      "photoUrl": "",
      "userId": "08908240325552421641"
     },
     "user_tz": -480
    },
    "id": "orDCj6ihgUMR",
    "outputId": "c4248d16-bd5a-498f-de3e-00bba3413653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/models/research\n"
     ]
    }
   ],
   "source": [
    "%cd /content/models/research\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "MODEL_FILE = MODEL + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "DEST_DIR = '/content/models/research/pretrained_model'\n",
    "\n",
    "if not (os.path.exists(MODEL_FILE)):\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "\n",
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "os.remove(MODEL_FILE)\n",
    "if (os.path.exists(DEST_DIR)):\n",
    "    shutil.rmtree(DEST_DIR)\n",
    "os.rename(MODEL, DEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20298,
     "status": "ok",
     "timestamp": 1621523283129,
     "user": {
      "displayName": "Camus Shen",
      "photoUrl": "",
      "userId": "08908240325552421641"
     },
     "user_tz": -480
    },
    "id": "pGhvAObeiIix",
    "outputId": "f78e7f40-25a2-4806-e3a3-49b8b3ca0b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/models/research/pretrained_model\n",
      "total 135M\n",
      "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
      "drwxr-xr-x 23 root   root  4.0K May 20 15:08 ..\n",
      "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
      "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
      "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
      "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
      "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
      "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
      "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
     ]
    }
   ],
   "source": [
    "!echo {DEST_DIR}\n",
    "!ls -alh {DEST_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 20294,
     "status": "ok",
     "timestamp": 1621523283131,
     "user": {
      "displayName": "Camus Shen",
      "photoUrl": "",
      "userId": "08908240325552421641"
     },
     "user_tz": -480
    },
    "id": "UHnxlfRznPP3",
    "outputId": "ba03f2df-1d36-407b-ffda-2db72636c438"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/models/research/pretrained_model/model.ckpt'"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
    "fine_tune_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dIhw7IdpLuiU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
    "\n",
    "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fG1nCNpUXcRU"
   },
   "outputs": [],
   "source": [
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "executionInfo": {
     "elapsed": 20315,
     "status": "error",
     "timestamp": 1621523283164,
     "user": {
      "displayName": "Camus Shen",
      "photoUrl": "",
      "userId": "08908240325552421641"
     },
     "user_tz": -480
    },
    "id": "YjtCbLF2i0wI",
    "outputId": "99c4d0ba-6b0f-4dbf-92d8-4614eceb3336"
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0e8e2f2ac78a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_num_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_map_pbtxt_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_fname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-caf3ddcde26a>\u001b[0m in \u001b[0;36mget_num_classes\u001b[0;34m(pbtxt_fname)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_num_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbtxt_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlabel_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_labelmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbtxt_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     categories = label_map_util.convert_label_map_to_categories(\n\u001b[1;32m      5\u001b[0m         label_map, max_num_classes=90, use_display_name=True)\n",
      "\u001b[0;32m/content/models/research/object_detection/utils/label_map_util.py\u001b[0m in \u001b[0;36mload_labelmap\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    166\u001b[0m   \"\"\"\n\u001b[1;32m    167\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mlabel_map_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0mlabel_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstring_int_label_map_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIntLabelMap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    115\u001b[0m       \u001b[0mstring\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \"\"\"\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m       \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m                                            \"File isn't open for reading\")\n\u001b[1;32m     79\u001b[0m       self._read_buf = _pywrap_file_io.BufferedInputStream(\n\u001b[0;32m---> 80\u001b[0;31m           compat.path_to_str(self.__name), 1024 * 512)\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /content/drive/label_map.pbtxt; No such file or directory"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open(pipeline_fname, 'w') as f:\n",
    "    \n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    # s = re.sub(\n",
    "    #     '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAz-ZQrfTegp"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GH0MEEanocn6"
   },
   "outputs": [],
   "source": [
    "!cat {pipeline_fname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f11w0uO3jFCB"
   },
   "outputs": [],
   "source": [
    "model_dir = 'training/'\n",
    "# Optionally remove content in output model directory to fresh start.\n",
    "!rm -rf {model_dir}\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0H2PZs-mSCmO"
   },
   "outputs": [],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip -o ngrok-stable-linux-amd64.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8o6r1o5SC5M"
   },
   "outputs": [],
   "source": [
    "LOG_DIR = model_dir\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ge1OX7gcSC7S"
   },
   "outputs": [],
   "source": [
    "get_ipython().system_raw('./ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjhPT9iPSJ6T"
   },
   "outputs": [],
   "source": [
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nC7_syR1SJ9F"
   },
   "outputs": [],
   "source": [
    "%cd slim\n",
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLPEGBV6mi3p"
   },
   "outputs": [],
   "source": [
    "!pip install lvis\n",
    "!pip install tf-models-official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjDHjhKQofT5"
   },
   "outputs": [],
   "source": [
    "import lvis\n",
    "!python /content/models/research/object_detection/model_main.py \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --num_eval_steps={num_eval_steps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KP-tUdtnRybs"
   },
   "outputs": [],
   "source": [
    "!ls {model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_1Nrqw3nqnCh"
   },
   "outputs": [],
   "source": [
    "# Legacy way of training(also works).\n",
    "# !python /content/models/research/object_detection/legacy/train.py --logtostderr --train_dir={model_dir} --pipeline_config_path={pipeline_fname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHoP90pUyKSq"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "output_directory = './fine_tuned_model'\n",
    "\n",
    "lst = os.listdir(model_dir)\n",
    "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
    "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
    "last_model = lst[steps.argmax()].replace('.meta', '')\n",
    "\n",
    "last_model_path = os.path.join(model_dir, last_model)\n",
    "print(last_model_path)\n",
    "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
    "    --input_type=image_tensor \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --output_directory={output_directory} \\\n",
    "    --trained_checkpoint_prefix={last_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usgBZvkz0nqD"
   },
   "outputs": [],
   "source": [
    "!ls {output_directory}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnDo1lonKgFr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
    "assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHqWkLBINYoI"
   },
   "outputs": [],
   "source": [
    "!ls -alh {pb_fname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAqyASIJqjae"
   },
   "outputs": [],
   "source": [
    "# Install the PyDrive wrapper & import libraries.\n",
    "# This only needs to be done once in a notebook.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "# This only needs to be done once in a notebook.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "fname = os.path.basename(pb_fname)\n",
    "# Create & upload a text file.\n",
    "uploaded = drive.CreateFile({'title': fname})\n",
    "uploaded.SetContentFile(pb_fname)\n",
    "uploaded.Upload()\n",
    "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bP0iMMnnr77"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(pb_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1TbL6Ox8q6Z"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download(label_map_pbtxt_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pql2QpemazE1"
   },
   "outputs": [],
   "source": [
    "files.download(pipeline_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w1AgBj1l0v_W"
   },
   "outputs": [],
   "source": [
    "# !tar cfz fine_tuned_model.tar.gz fine_tuned_model\n",
    "# from google.colab import files\n",
    "# files.download('fine_tuned_model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pzj9A4e5mj5l"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_CKPT = pb_fname\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = label_map_pbtxt_fname\n",
    "\n",
    "# If you want to test the code with your images, just add images files to the PATH_TO_TEST_IMAGES_DIR.\n",
    "PATH_TO_TEST_IMAGES_DIR =  os.path.join(repo_dir_path, \"test\")\n",
    "\n",
    "assert os.path.isfile(pb_fname)\n",
    "assert os.path.isfile(PATH_TO_LABELS)\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n",
    "assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n",
    "print(TEST_IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CG5YUMdg1Po7"
   },
   "outputs": [],
   "source": [
    "%cd /content/models/research/object_detection\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "\n",
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map, max_num_classes=num_classes, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (12, 8)\n",
    "\n",
    "\n",
    "def run_inference_for_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "            # Get handles to input and output tensors\n",
    "            ops = tf.get_default_graph().get_operations()\n",
    "            all_tensor_names = {\n",
    "                output.name for op in ops for output in op.outputs}\n",
    "            tensor_dict = {}\n",
    "            for key in [\n",
    "                'num_detections', 'detection_boxes', 'detection_scores',\n",
    "                'detection_classes', 'detection_masks'\n",
    "            ]:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                        tensor_name)\n",
    "            if 'detection_masks' in tensor_dict:\n",
    "                # The following processing is only for single image\n",
    "                detection_boxes = tf.squeeze(\n",
    "                    tensor_dict['detection_boxes'], [0])\n",
    "                detection_masks = tf.squeeze(\n",
    "                    tensor_dict['detection_masks'], [0])\n",
    "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "                real_num_detection = tf.cast(\n",
    "                    tensor_dict['num_detections'][0], tf.int32)\n",
    "                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n",
    "                                           real_num_detection, -1])\n",
    "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n",
    "                                           real_num_detection, -1, -1])\n",
    "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "                detection_masks_reframed = tf.cast(\n",
    "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                # Follow the convention by adding back the batch dimension\n",
    "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                    detection_masks_reframed, 0)\n",
    "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "            # Run inference\n",
    "            output_dict = sess.run(tensor_dict,\n",
    "                                   feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "            output_dict['num_detections'] = int(\n",
    "                output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict[\n",
    "                'detection_classes'][0].astype(np.uint8)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "            if 'detection_masks' in output_dict:\n",
    "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict\n",
    "\n",
    "\n",
    "for image_path in TEST_IMAGE_PATHS:\n",
    "    image = Image.open(image_path)\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        image_np,\n",
    "        output_dict['detection_boxes'],\n",
    "        output_dict['detection_classes'],\n",
    "        output_dict['detection_scores'],\n",
    "        category_index,\n",
    "        instance_masks=output_dict.get('detection_masks'),\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=8)\n",
    "    plt.figure(figsize=IMAGE_SIZE)\n",
    "    plt.imshow(image_np)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "“tensorflow-object-detection-training-colab.ipynb”的副本",
   "provenance": [
    {
     "file_id": "https://github.com/Tony607/object_detection_demo/blob/master/tensorflow_object_detection_training_colab.ipynb",
     "timestamp": 1621438814037
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
